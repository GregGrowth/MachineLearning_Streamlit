# import streamlit as st
# import pandas as pd
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split
# from lazypredict.Supervised import LazyClassifier
# from sklearn.linear_model import LogisticRegression
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.metrics import classification_report, confusion_matrix
#
# # Charger le fichier CSV depuis le local
# @st.cache_data
# def load_data():
#     return pd.read_csv("./data/vin.csv", index_col=0)
#
# df = load_data()
#
# st.title("Projet Machine Learning üéà")
#
# # S√©parer les variables explicatives (X) et la variable cible (y)
# X = df.drop(columns=['target'])
# y = df['target']
#
# # Page principale de classification
# def classification_page():
#     st.caption("Bienvenue dans le Playground de Classification")
#
#     # S√©lection des param√®tres dans la sidebar
#     st.sidebar.markdown("### Param√®tres")
#
#     # Slider pour la taille du jeu de test
#     test_size = st.sidebar.slider(
#         "Taille du jeu de test (%)", 5, 50, 20, help="Entrez une valeur comprise entre 5 et 50"
#     ) / 100
#
#     # Nombre al√©atoire pour reproduire les r√©sultats
#     random_state = st.sidebar.number_input("Random state", value=42, help="A d√©finir pour reproduire les r√©sultats")
#
#     # S√©paration des donn√©es d'entra√Ænement et de test
#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
#
#     # Affichage de la taille des ensembles d'entra√Ænement et de test
#     st.subheader("Taille des ensembles d'entra√Ænement et de test")
#     st.write(f"Taille de l'ensemble d'entra√Ænement : {X_train.shape[0]}")
#     st.write(f"Taille de l'ensemble de test : {X_test.shape[0]}")
#
#     # S√©lection des variables explicatives par l'utilisateur
#     st.sidebar.markdown("## S√©lection des variables explicatives")
#     selected_columns = st.sidebar.multiselect("S√©lectionnez les variables explicatives", options=X.columns.tolist(),
#                                               default=X.columns.tolist())
#
#     if selected_columns:
#         X_train = X_train[selected_columns]
#         X_test = X_test[selected_columns]
#     else:
#         st.warning("Aucune colonne s√©lectionn√©e pour l'entra√Ænement.")
#
#     # Initialiser y_pred et report
#     y_pred = None
#     report = None
#
#     # Cr√©ation des onglets
#     tab1, tab2, tab3, tab4, tab5 = st.tabs(
#         ["Aper√ßu du dataset", "LazyPredict", "Choix du mod√®le", "Pr√©visualisation du mod√®le", "Comparaison des mod√®les"]
#     )
#
#     # Onglet 1 : Aper√ßu du dataset
#     with tab1:
#         st.subheader("Aper√ßu du dataset avant la phase de Machine Learning")
#         st.write(df)
#
#     # Onglet 2 : LazyPredict
#     with tab2:
#         st.subheader("LazyPredict: Comparaison rapide de plusieurs mod√®les")
#         if st.button("Lancer LazyPredict"):
#             lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)
#             models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)
#             st.write("Voici les r√©sultats des diff√©rents mod√®les :")
#             st.dataframe(models)
#
#     # Onglet 3 : Choix du mod√®le ML
#     with tab3:
#         st.subheader("Choisissez un mod√®le pour l'entra√Ænement")
#
#         model_choice = st.selectbox("Choisissez un mod√®le",
#                                     ["Logistic Regression", "Random Forest", "K-Nearest Neighbors"])
#
#         # Param√©trage selon le mod√®le choisi
#         if model_choice == "Logistic Regression":
#             max_iter = st.number_input("Max Iterations", value=100)
#             model = LogisticRegression(max_iter=max_iter)
#         elif model_choice == "Random Forest":
#             n_estimators = st.number_input("Nombre d'arbres", value=100)
#             model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)
#         elif model_choice == "K-Nearest Neighbors":
#             n_neighbors = st.number_input("Nombre de voisins", value=5)
#             model = KNeighborsClassifier(n_neighbors=n_neighbors)
#
#         # Entra√Æner le mod√®le
#         if st.button(f"Lancer {model_choice}"):
#             model.fit(X_train, y_train)
#             y_pred = model.predict(X_test)
#             report = classification_report(y_test, y_pred, output_dict=True)
#             st.write(f"Rapport de classification pour {model_choice} :")
#             st.json(report)
#
#     # Onglet 4 : Pr√©visualisation du mod√®le
#     with tab4:
#         st.subheader("Pr√©visualisation des r√©sultats")
#
#         # V√©rifier si y_pred a √©t√© g√©n√©r√©
#         if y_pred is not None:
#             cm = confusion_matrix(y_test, y_pred)
#             st.write("Matrice de confusion :")
#             fig, ax = plt.subplots()
#             sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
#             st.pyplot(fig)
#         else:
#             st.write("Aucune pr√©diction n'a √©t√© faite pour afficher la matrice de confusion.")
#
#     # Onglet 5 : Comparaison des mod√®les
#     with tab5:
#         st.subheader("Comparaison des mod√®les")
#         st.write("√Ä venir.")
#
# # Ex√©cuter la page de classification
# classification_page()
#
# with tab1:
#     st.subheader("Pr√©traitement des donn√©es")
#
#     # S√©lection des colonnes explicatives et de la cible
#     features = st.multiselect("S√©lectionnez les features (X)", data.columns.tolist())
#     target = st.selectbox("S√©lectionnez la cible (y)", data.columns.tolist())
#
#     if not features or not target:
#         st.warning("Veuillez s√©lectionner les colonnes pour X et y.")
#         return
#
#     X = data[features]
#     y = data[target]
#
#     # Split et seed dans la sidebar
#     test_size = st.sidebar.slider("Taille du jeu de test (%)", min_value=10, max_value=50, value=30) / 100
#     random_state = st.sidebar.slider("Seed pour la reproduction", min_value=0, max_value=100, value=42)
#
#     # Normalisation des donn√©es (facultatif)
#     if st.checkbox("Appliquer la normalisation des donn√©es"):
#         scaler = StandardScaler()
#         X = scaler.fit_transform(X)
#
# with tab2:
#     st.subheader("Mod√©lisation")
#
#     # LazyPredict pour les utilisateurs d√©butants
#     if st.checkbox("Utiliser LazyPredict pour voir les mod√®les de base"):
#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
#         lazy_clf = LazyClassifier()
#         models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)
#         st.write("### Comparaison des mod√®les :")
#         st.write(models)
#
#     st.write("### Choisissez un mod√®le de classification :")
#     model_choice = st.selectbox("Mod√®le", ["Logistic Regression", "K-NN", "Random Forest"])
#
#     # Choix des mod√®les et options
#     if model_choice == "Logistic Regression":
#         model = LogisticRegression()
#     elif model_choice == "K-NN":
#         n_neighbors = st.slider("Nombre de voisins (k)", min_value=1, max_value=20, value=5)
#         model = KNeighborsClassifier(n_neighbors=n_neighbors)
#     elif model_choice == "Random Forest":
#         n_estimators = st.slider("Nombre d'arbres", min_value=10, max_value=100, value=50)
#         model = RandomForestClassifier(n_estimators=n_estimators)
#
#     # Bouton pour ex√©cuter le mod√®le
#     if st.button("Run le mod√®le"):
#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
#         model.fit(X_train, y_train)
#         st.success("Le mod√®le a √©t√© entra√Æn√© avec succ√®s.")
#
# with tab3:
#     st.subheader("√âvaluation")
#
#     if st.button("√âvaluer le mod√®le"):
#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
#         y_pred = model.predict(X_test)
#
#         # Matrice de confusion
#         st.write("#### Matrice de confusion")
#         conf_matrix = confusion_matrix(y_test, y_pred)
#         fig, ax = plt.subplots()
#         sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", ax=ax)
#         st.pyplot(fig)
#
#         # Rapport de classification
#         st.write("#### Rapport de classification")
#         report = classification_report(y_test, y_pred, output_dict=True)
#         st.write(pd.DataFrame(report).transpose())
#
# import streamlit as st
# import pandas as pd
# from sklearn.model_selection import train_test_split
# from sklearn.linear_model import LogisticRegression
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.ensemble import RandomForestClassifier
# from lazypredict.Supervised import LazyClassifier
# from sklearn.metrics import classification_report, confusion_matrix
# import matplotlib.pyplot as plt
# import seaborn as sns
#
# # V√©rifier si df est d√©j√† charg√© dans st.session_state
# if 'df' not in st.session_state:
#     # Charger le fichier CSV dans df
#     st.session_state['df'] = pd.read_csv("./data/vin.csv").drop(columns=['Unnamed: 0'])
# df = st.session_state['df']  # R√©cup√©rer les donn√©es depuis st.session_state
#
# # Fonction principale pour la classification
# def classification_page():
#     st.caption("Playground ML - Classification")
#
#     # Cr√©ation des onglets principaux
#     tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(
#         ["S√©lection des variables", "Aper√ßu du dataset", "Mod√©lisation LazyPredict",
#          "Mod√©lisation Autres", "√âvaluation", "Comparaison"]
#     )
#
#     # Onglet 1 : S√©lection des variables
#     with tab1:
#         st.subheader("S√©lection des variables explicatives (X) et de la cible (y)")
#
#         # S√©lection des variables explicatives par l'utilisateur
#         selected_columns = st.multiselect("S√©lectionnez les variables explicatives (X)", options=df.columns.tolist(), default=[])
#
#         # S√©lection de la cible (y) sans s√©lection par d√©faut
#         target = st.selectbox("S√©lectionnez la cible (y)", options=[col for col in df.columns if col not in selected_columns], index=0)
#
#         # Stocker X et y dans st.session_state
#         if selected_columns and target:
#             st.session_state['X'] = df[selected_columns]
#             st.session_state['y'] = df[target]
#
#             st.write("### Variables explicatives (X) s√©lectionn√©es :")
#             st.write(selected_columns)
#             st.write("### Cible (y) s√©lectionn√©e :")
#             st.write(target)
#
#             # Bouton pour valider le choix
#             if st.button("Valider votre choix"):
#                 confirm = st.radio("Voulez-vous valider votre choix ?", ("Oui", "Non"))
#
#                 if confirm == "Oui":
#                     st.success("Votre s√©lection a √©t√© valid√©e.")
#                 elif confirm == "Non":
#                     st.warning("Veuillez refaire votre s√©lection.")
#
#         else:
#             st.warning("Veuillez s√©lectionner les colonnes pour X et y.")
#
#     # Onglet 2 : Aper√ßu du dataset
#     with tab2:
#         st.subheader("Aper√ßu du dataset")
#         #
#         # if st.session_state['X'] is not None and st.session_state['y'] is not None:
#         #     # Appliquer des couleurs pour diff√©rencier les colonnes X et la cible y
#         #     styled_data = df.style.apply(
#         #         lambda x: ['background-color: lightblue' if col in st.session_state['X'].columns else
#         #                    'background-color: lightgreen' if col == st.session_state['y'].name else ''
#         #                    for col in df.columns], axis=1
#         #     )
#         #     st.dataframe(styled_data)
#         # else:
#         #     st.write(df)  # Affiche les donn√©es sans coloration si aucune s√©lection n'est faite
#
#     # Onglet 3 : Mod√©lisation LazyPredict
#     with tab3:
#         st.subheader("Mod√©lisation rapide avec LazyPredict")
#
#         # # V√©rifier que les variables X et y sont bien d√©finies avant de continuer
#         # if st.session_state['X'] is not None and st.session_state['y'] is not None:
#         #     test_size = st.slider("Taille du jeu de test (%)", 5, 50, 20) / 100
#         #     random_state = st.number_input("Random state", value=42)
#         #
#         #     X_train, X_test, y_train, y_test = train_test_split(st.session_state['X'], st.session_state['y'],
#         #                                                         test_size=test_size, random_state=random_state)
#         #
#         #     if st.button("Lancer LazyPredict"):
#         #         lazy_clf = LazyClassifier(verbose=0, ignore_warnings=True)
#         #         models, predictions = lazy_clf.fit(X_train, X_test, y_train, y_test)
#         #         st.write("R√©sultats LazyPredict :")
#         #         st.dataframe(models)
#         # else:
#         #     st.warning("Veuillez d'abord s√©lectionner les variables explicatives et la cible dans l'onglet 1.")
#
#     # Onglet 4 : Mod√©lisation Autres avec sous-onglets
#     with tab4:
#         st.subheader("Mod√©lisation Avanc√©e")
#
#         # V√©rifier que les variables X et y sont bien d√©finies avant de continuer
#         if st.session_state['X'] is not None and st.session_state['y'] is not None:
#             subtab1, subtab2, subtab3, subtab4 = st.tabs(
#                 ["Logistic Regression", "Random Forest", "K-Nearest Neighbors", "Autres"]
#             )
#
#             # Sous-onglet Logistic Regression
#             with subtab1:
#                 st.subheader("Logistic Regression")
#                 max_iter = st.number_input("Max Iterations", value=100)
#                 model_lr = LogisticRegression(max_iter=max_iter)
#                 if st.button("Entra√Æner Logistic Regression"):
#                     model_lr.fit(X_train, y_train)
#                     st.write("Mod√®le Logistic Regression entra√Æn√©.")
#
#             # Sous-onglet Random Forest
#             with subtab2:
#                 st.subheader("Random Forest")
#                 n_estimators = st.number_input("Nombre d'arbres", value=100)
#                 model_rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)
#                 if st.button("Entra√Æner Random Forest"):
#                     model_rf.fit(X_train, y_train)
#                     st.write("Mod√®le Random Forest entra√Æn√©.")
#
#             # Sous-onglet K-Nearest Neighbors
#             with subtab3:
#                 st.subheader("K-Nearest Neighbors")
#                 n_neighbors = st.number_input("Nombre de voisins", value=5)
#                 model_knn = KNeighborsClassifier(n_neighbors=n_neighbors)
#                 if st.button("Entra√Æner K-NN"):
#                     model_knn.fit(X_train, y_train)
#                     st.write("Mod√®le K-NN entra√Æn√©.")
#
#             # Sous-onglet Autres mod√®les
#             with subtab4:
#                 st.subheader("Autres mod√®les")
#                 st.write("S√©lectionnez et entra√Ænez d'autres mod√®les √† tester.")
#         else:
#             st.warning("Veuillez d'abord s√©lectionner les variables explicatives et la cible dans l'onglet 1.")
#
#     # Onglet 5 : √âvaluation
#     with tab5:
#         st.subheader("√âvaluation des mod√®les")
#         # Evaluation des mod√®les bas√©s sur les r√©sultats de l'entra√Ænement
#         st.write("√Ä impl√©menter : S√©lectionner un mod√®le pour l'√©valuation.")
#
#     # Onglet 6 : Comparaison (vide pour l'instant)
#     with tab6:
#         st.subheader("Comparaison des mod√®les")
#         st.write("Fonctionnalit√© √† venir.")
#
# # Ex√©cuter la page de classification
# classification_page()